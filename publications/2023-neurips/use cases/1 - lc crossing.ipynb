{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762119d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcdb.db import LCDB\n",
    "from lcdb.analysis.util import LearningCurveExtractor, merge_curves\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68815a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████████▋                                                                                                                                 | 4/25 [00:06<00:36,  1.74s/it]"
     ]
    }
   ],
   "source": [
    "workflows = [\n",
    "    \"lcdb.workflow.sklearn.KNNWorkflow\",\n",
    "    \"lcdb.workflow.sklearn.LibLinearWorkflow\",\n",
    "    \"lcdb.workflow.sklearn.LibSVMWorkflow\",\n",
    "    \"lcdb.workflow.sklearn.TreesEnsembleWorkflow\"\n",
    "]\n",
    "\n",
    "openmlid = 6\n",
    "workflow = workflows[1]\n",
    "\n",
    "# retrieve learning curve objects\n",
    "lcdb = LCDB()\n",
    "df = lcdb.query(\n",
    "    openmlids=[openmlid],\n",
    "    workflows=[workflow],\n",
    "    return_generator=False,\n",
    "    processors={\n",
    "        \"learning_curve\": LearningCurveExtractor(\n",
    "            metrics=[\"error_rate\"],\n",
    "            folds=[\"train\", \"val\"]\n",
    "        )\n",
    "    },\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# group by configurations\n",
    "config_cols = [c for c in df.columns if c.startswith(\"p:\")]\n",
    "df = df.groupby(config_cols).agg({\"learning_curve\": merge_curves})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984cc34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_schedule = df[\"learning_curve\"].iloc[0].anchors_size\n",
    "print(max_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0479c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"learning_curve\"].apply(lambda x: x.pad_anchors_size(max_schedule, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb1c7b",
   "metadata": {},
   "source": [
    "# Plot of learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cfb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "best_score = np.inf\n",
    "for lc in df[\"learning_curve\"]:\n",
    "    schedule = lc.anchors_size\n",
    "    lc = lc.values[0, 1, :, :, :, :, -1] if lc.is_iteration_wise_curve else lc.values[0, 1] # validation error rate\n",
    "    \n",
    "    if np.any(~np.isnan(lc)):\n",
    "        mu = np.nanmean(lc, axis=(0, 1, 2)).squeeze()\n",
    "        std = np.nanstd(lc, axis=(0, 1, 2)).squeeze()\n",
    "        ax.plot(schedule, mu)\n",
    "        ax.fill_between(schedule, mu - std, mu + std, alpha=0.1)\n",
    "        if not np.isnan(mu[-1]) and mu[-1] < best_score:\n",
    "            best_score = mu[-1]\n",
    "print(best_score)\n",
    "ax.axhline(best_score, color=\"black\", linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346716f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve_crossing_evaluation(df):\n",
    "    \n",
    "    schedule = df[\"learning_curve\"].iloc[0].anchors_size\n",
    "    \n",
    "    # compute diffs at different anchors\n",
    "    diffs = np.zeros((len(df), len(df), len(df[\"learning_curve\"].iloc[0].test_seeds), len(df[\"learning_curve\"].iloc[0].val_seeds), len(df[\"learning_curve\"].iloc[0].workflow_seeds), len(schedule)))\n",
    "    for i, lc1 in enumerate(df[\"learning_curve\"]):\n",
    "        curve1 = lc1.values[0, 1]\n",
    "        for j, lc2 in enumerate(df[\"learning_curve\"]):\n",
    "            curve2 = lc2.values[0, 1]\n",
    "            diffs[i, j] = curve1 - curve2\n",
    "    diffs_bin = diffs > 0\n",
    "    \n",
    "    # define start index\n",
    "    start_index = 0\n",
    "    \n",
    "    # compute P(A starts lower than B)\n",
    "    probs_a_starts_higher_than_b = diffs_bin[:,:,:,:,:,start_index].mean(axis=(2, 3, 4))\n",
    "    \n",
    "    # compute P(A starts lower than B and finishes higher)\n",
    "    probs_a_strats_higher_than_b_and_ends_lower_than_b = (diffs_bin[:,:,:,:,:,start_index] & ~diffs_bin[:,:,:,:,:,-1]).mean(axis=(2, 3, 4))\n",
    "    \n",
    "    # figure for probability of crossing\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    sb.heatmap(probs_a_starts_higher_than_b, cmap=\"Greens\", ax=axs[0])\n",
    "    sb.heatmap(probs_a_strats_higher_than_b_and_ends_lower_than_b, cmap=\"Greens\", ax=axs[1])\n",
    "    sb.heatmap(probs_a_strats_higher_than_b_and_ends_lower_than_b / np.maximum(10**-10, probs_a_starts_higher_than_b), cmap=\"Greens\", ax=axs[2])\n",
    "    axs[0].set_title(r\"$\\mathbb{P}$(A starts higher than B)\")\n",
    "    axs[1].set_title(r\"$\\mathbb{P}$(A starts higher than B and ends lower)\")\n",
    "    axs[2].set_title(r\"$\\mathbb{P}$(A and ends lower than B|A starts higher than B)\")\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"hp config A\")\n",
    "        ax.set_ylabel(\"hp config B\")\n",
    "    fig.savefig(f\"plots/lc_crossing_{openmlid}_{workflow}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    # gaps to the finally best (at the respective budget)\n",
    "    idx_of_best = np.argmin([np.nanmean(lc.values[0, 1, :, :, :, -1]) if np.count_nonzero(~np.isnan(lc.values[0, 1, :, :, :, -1])) > 0 else np.inf for lc in df[\"learning_curve\"]])\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 4))\n",
    "    ax = axs[0]\n",
    "    for diff in diffs[:,idx_of_best]:\n",
    "        mu = diff.mean(axis=(0, 1, 2))\n",
    "        std = diff.std(axis=(0, 1, 2))\n",
    "        ax.plot(schedule, mu)\n",
    "        ax.fill_between(schedule, mu - std, mu + std, alpha=0.1)\n",
    "    ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "    ax.set_title(\"Gaps to finally best configuration along budget\")\n",
    "    ax.set_xlabel(\"Budget $b$ (sample size)\")\n",
    "    ax.set_ylabel(\"Gap in error rate to finally best config\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    \n",
    "    # distribution of final gaps based on selections by budgets\n",
    "    gaps_by_budget = {}\n",
    "    for i, budget in enumerate(schedule):\n",
    "        mean_scores_at_budget = []\n",
    "        for lc in df[\"learning_curve\"]:\n",
    "            lc_slice = lc.values[0, 1, :, :, :, i]\n",
    "            mean_scores_at_budget.append(np.nanmean(lc_slice) if np.count_nonzero(~np.isnan(lc_slice)) > 0 else np.inf)\n",
    "        idx_of_best_at_budget = np.argmin(mean_scores_at_budget)\n",
    "        gaps_by_budget[budget] = diffs[idx_of_best_at_budget,idx_of_best, :, :, :, -1].flatten()\n",
    "        gaps_by_budget[budget] = gaps_by_budget[budget][~np.isnan(gaps_by_budget[budget])]\n",
    "    ax = axs[1]\n",
    "    ax.boxplot([gaps_by_budget[b] for b in schedule])\n",
    "    ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "    ax.set_xticklabels(schedule, rotation=90)\n",
    "    ax.set_title(\"Regret at full dataset size when picking best config at budget $b$\")\n",
    "    ax.set_xlabel(\"Budget $b$ (sample size)\")\n",
    "    ax.set_ylabel(\"Regrets at full dataset size (across seeds)\")\n",
    "    fig.savefig(f\"plots/regrets_{openmlid}_{workflow}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    # figures for diffs\n",
    "    for i in range(len(schedule)):\n",
    "        fig, ax = plt.subplots()\n",
    "        sb.heatmap(diffs.mean(axis=(2, 3, 4))[:, :, i], ax=ax, vmin=-1, vmax=1, cmap=\"seismic\")\n",
    "        plt.show()\n",
    "    \n",
    "learning_curve_crossing_evaluation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f77ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
